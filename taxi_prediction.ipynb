{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Taxi Demand Prediction</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> DATA DICTIONARY </h3>\n",
    "<table>\n",
    "<th>Field Name <th>Description\n",
    "<tr> <td>VendorID <td>A code indicating the TPEP provider that provided the record.\n",
    "1= Creative Mobile Technologies, LLC; 2= VeriFone Inc.\n",
    "<tr>\n",
    "<td>tpep_pickup_datetime <td> The date and time when the meter was engaged.\n",
    "<tr>\n",
    "<td>tpep_dropoff_datetime <td>The date and time when the meter was disengaged.\n",
    "<tr>\n",
    "<td>Passenger_count <td>The number of passengers in the vehicle.\n",
    "This is a driver-entered value.\n",
    "<tr>\n",
    "<td>Trip_distance <td>The elapsed trip distance in miles reported by the taximeter.\n",
    "<tr>\n",
    "<td>PULocationID <td>TLC Taxi Zone in which the taximeter was engaged\n",
    "<tr><td>DOLocationID <td>TLC Taxi Zone in which the taximeter was disengaged\n",
    "<tr><td>RateCodeID <td>The final rate code in effect at the end of the trip.\n",
    "1= Standard rate\n",
    "2=JFK\n",
    "3=Newark\n",
    "4=Nassau or Westchester\n",
    "5=Negotiated fare\n",
    "6=Group ride\n",
    "<tr>\n",
    "<td>Store_and_fwd_flag <td>This flag indicates whether the trip record was held in vehicle\n",
    "memory before sending to the vendor, aka “store and forward,”\n",
    "because the vehicle did not have a connection to the server.\n",
    "Y= store and forward trip\n",
    "N= not a store and forward trip\n",
    "<tr>\n",
    "<td>Payment_type <td>A numeric code signifying how the passenger paid for the trip.\n",
    "1= Credit card\n",
    "2= Cash\n",
    "3= No charge\n",
    "4= Dispute\n",
    "5= Unknown\n",
    "6= Voided trip\n",
    "<tr><td>\n",
    "Fare_amount <td>The time-and-distance fare calculated by the meter.\n",
    "<tr><td>\n",
    "Extra <td>Miscellaneous extras and surcharges. Currently, this only includes\n",
    "the $0.50 and $1 rush hour and overnight charges.\n",
    "<tr><td>\n",
    "MTA_tax <td>$0.50 MTA tax that is automatically triggered based on the metered\n",
    "rate in use.\n",
    "<tr><td>\n",
    "Improvement_surcharge <td>$0.30 improvement surcharge assessed trips at the flag drop. The\n",
    "improvement surcharge began being levied in 2015.\n",
    "<tr><td>\n",
    "Tip_amount <td>Tip amount – This field is automatically populated for credit card\n",
    "tips. Cash tips are not included.\n",
    "<tr><td>\n",
    "Tolls_amount <td>Total amount of all tolls paid in trip.\n",
    "<tr><td>\n",
    "Total_amount <td>The total amount charged to passengers. Does not include cash tips.\n",
    "<tr><td>\n",
    "Congestion_Surcharge <td>Total amount collected in trip for NYS congestion surcharge.\n",
    "<tr><td>\n",
    "Airport_fee <td>$1.25 for pick up only at LaGuardia and John F. Kennedy Airports\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (9.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from pyarrow) (1.21.5)\n",
      "\n",
      "Requirement already satisfied: fastparquet in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: numpy>=1.18 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from fastparquet) (1.21.5)\n",
      "Requirement already satisfied: pandas>=1.1.0 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from fastparquet) (1.4.2)\n",
      "Requirement already satisfied: cramjam>=2.3.0 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from fastparquet) (2.5.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from fastparquet) (2022.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from fastparquet) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->fastparquet) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from pandas>=1.1.0->fastparquet) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=1.1.0->fastparquet) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\satvik_dell\\anaconda3\\lib\\site-packages (from packaging->fastparquet) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyarrow\n",
    "%pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"yellow_tripdata_2022-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime',\n",
       "       'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag',\n",
       "       'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra',\n",
       "       'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge',\n",
       "       'total_amount', 'congestion_surcharge', 'airport_fee'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Columns with Null Values** : \n",
    "    <ol>\n",
    "    \n",
    "        passenger_count\n",
    "\n",
    "        RatecodeID\n",
    "\n",
    "        store_and_fwd_flag\n",
    "\n",
    "        congestion_surcharge\n",
    "\n",
    "        airport_fee\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, store_and_fwd_flag, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['VendorID'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Handling Null Values of Airport_fee and Congestion Surcharge </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Airport Fee : All NaN values replaced by zero\n",
    "\n",
    "Congestion Surcharge : All NaN values replaced by\n",
    "$$\n",
    "Total amount -(fare amount+extra+mta tax+tip amount+tolls amount+improvement surcharge)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.core.umath import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_value_handled(df):\n",
    "    df['airport_fee']= df['airport_fee'].fillna(0)\n",
    "    df.loc[df['airport_fee'].isnull()]\n",
    "    df['congestion_surcharge']= df['congestion_surcharge'].fillna(df['total_amount']-(df['fare_amount']+df['extra']+df['mta_tax']+df['tip_amount']+df['tolls_amount']+df['improvement_surcharge']))\n",
    "    df=df.drop('store_and_fwd_flag',axis=1)\n",
    "    average=df['total_amount']/df['trip_distance']\n",
    "    mean=np.mean(average[np.isfinite(average)])\n",
    "    df['passenger_count']= df['passenger_count'].fillna(0)\n",
    "    df['RatecodeID']= df['RatecodeID'].fillna(0)\n",
    "    return(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = null_value_handled(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:35:40</td>\n",
       "      <td>2022-01-01 00:53:29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>14.50</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>21.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-01-01 00:33:43</td>\n",
       "      <td>2022-01-01 00:42:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:53:21</td>\n",
       "      <td>2022-01-01 01:02:19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>1</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:25:21</td>\n",
       "      <td>2022-01-01 00:35:23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-01 00:36:48</td>\n",
       "      <td>2022-01-01 01:14:20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>23.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463926</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31 23:36:53</td>\n",
       "      <td>2022-01-31 23:42:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>8.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.69</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463927</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31 23:44:22</td>\n",
       "      <td>2022-01-31 23:55:01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>16.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.45</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463928</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31 23:39:00</td>\n",
       "      <td>2022-01-31 23:50:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>113</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>11.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.52</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463929</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31 23:36:42</td>\n",
       "      <td>2022-01-31 23:48:45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>12.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>15.70</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463930</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-01-31 23:46:00</td>\n",
       "      <td>2022-02-01 00:13:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>186</td>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>25.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>35.06</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2463931 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0               1  2022-01-01 00:35:40   2022-01-01 00:53:29              2.0   \n",
       "1               1  2022-01-01 00:33:43   2022-01-01 00:42:07              1.0   \n",
       "2               2  2022-01-01 00:53:21   2022-01-01 01:02:19              1.0   \n",
       "3               2  2022-01-01 00:25:21   2022-01-01 00:35:23              1.0   \n",
       "4               2  2022-01-01 00:36:48   2022-01-01 01:14:20              1.0   \n",
       "...           ...                  ...                   ...              ...   \n",
       "2463926         2  2022-01-31 23:36:53   2022-01-31 23:42:51              0.0   \n",
       "2463927         2  2022-01-31 23:44:22   2022-01-31 23:55:01              0.0   \n",
       "2463928         2  2022-01-31 23:39:00   2022-01-31 23:50:00              0.0   \n",
       "2463929         2  2022-01-31 23:36:42   2022-01-31 23:48:45              0.0   \n",
       "2463930         2  2022-01-31 23:46:00   2022-02-01 00:13:00              0.0   \n",
       "\n",
       "         trip_distance  RatecodeID  PULocationID  DOLocationID  payment_type  \\\n",
       "0                 3.80         1.0           142           236             1   \n",
       "1                 2.10         1.0           236            42             1   \n",
       "2                 0.97         1.0           166           166             1   \n",
       "3                 1.09         1.0           114            68             2   \n",
       "4                 4.30         1.0            68           163             1   \n",
       "...                ...         ...           ...           ...           ...   \n",
       "2463926           1.32         0.0            90           170             0   \n",
       "2463927           4.19         0.0           107            75             0   \n",
       "2463928           2.10         0.0           113           246             0   \n",
       "2463929           2.92         0.0           148           164             0   \n",
       "2463930           8.94         0.0           186           181             0   \n",
       "\n",
       "         fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0              14.50    3.0      0.5        3.65           0.0   \n",
       "1               8.00    0.5      0.5        4.00           0.0   \n",
       "2               7.50    0.5      0.5        1.76           0.0   \n",
       "3               8.00    0.5      0.5        0.00           0.0   \n",
       "4              23.50    0.5      0.5        3.00           0.0   \n",
       "...              ...    ...      ...         ...           ...   \n",
       "2463926         8.00    0.0      0.5        2.39           0.0   \n",
       "2463927        16.80    0.0      0.5        4.35           0.0   \n",
       "2463928        11.22    0.0      0.5        2.00           0.0   \n",
       "2463929        12.40    0.0      0.5        0.00           0.0   \n",
       "2463930        25.48    0.0      0.5        6.28           0.0   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                          0.3         21.95                   2.5   \n",
       "1                          0.3         13.30                   0.0   \n",
       "2                          0.3         10.56                   0.0   \n",
       "3                          0.3         11.80                   2.5   \n",
       "4                          0.3         30.30                   2.5   \n",
       "...                        ...           ...                   ...   \n",
       "2463926                    0.3         13.69                   2.5   \n",
       "2463927                    0.3         24.45                   2.5   \n",
       "2463928                    0.3         16.52                   2.5   \n",
       "2463929                    0.3         15.70                   2.5   \n",
       "2463930                    0.3         35.06                   2.5   \n",
       "\n",
       "         airport_fee  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "...              ...  \n",
       "2463926          0.0  \n",
       "2463927          0.0  \n",
       "2463928          0.0  \n",
       "2463929          0.0  \n",
       "2463930          0.0  \n",
       "\n",
       "[2463931 rows x 18 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VendorID                          int64\n",
       "tpep_pickup_datetime     datetime64[ns]\n",
       "tpep_dropoff_datetime    datetime64[ns]\n",
       "passenger_count                 float64\n",
       "trip_distance                   float64\n",
       "RatecodeID                      float64\n",
       "PULocationID                      int64\n",
       "DOLocationID                      int64\n",
       "payment_type                      int64\n",
       "fare_amount                     float64\n",
       "extra                           float64\n",
       "mta_tax                         float64\n",
       "tip_amount                      float64\n",
       "tolls_amount                    float64\n",
       "improvement_surcharge           float64\n",
       "total_amount                    float64\n",
       "congestion_surcharge            float64\n",
       "airport_fee                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [VendorID, tpep_pickup_datetime, tpep_dropoff_datetime, passenger_count, trip_distance, RatecodeID, PULocationID, DOLocationID, payment_type, fare_amount, extra, mta_tax, tip_amount, tolls_amount, improvement_surcharge, total_amount, congestion_surcharge, airport_fee]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['RatecodeID'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix(s):\n",
    "    # return time.mktime(datetime.datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\").timetuple())\n",
    "    return (s- np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_trip_times(df):\n",
    "\n",
    "    duration = df[['tpep_pickup_datetime', 'tpep_dropoff_datetime']]\n",
    "# pickups and dropoffs to unix time\n",
    "    duration_pickup = [convert_to_unix(x) for x in duration['tpep_pickup_datetime'].values]\n",
    "    duration_drop = [convert_to_unix(x) for x in duration['tpep_dropoff_datetime'].values]\n",
    "# calculate duration of trips\n",
    "    durations = (np.array(duration_drop) - np.array(duration_pickup))/float(60)\n",
    "    # append durations of trips and speed in miles/hr to a new dataframe\n",
    "    new_frame = df[['passenger_count', 'trip_distance', 'PULocationID','DOLocationID','total_amount']].copy()\n",
    "    new_frame['trip_time'] = durations\n",
    "    new_frame['pickup_times']= duration_pickup\n",
    "    new_frame['Speed'] = 60 *(new_frame['trip_distance']/new_frame['trip_time'])\n",
    "    \n",
    "    return new_frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATVIK_DELL\\AppData\\Local\\Temp\\ipykernel_22716\\1101715340.py:3: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  return (s- np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n"
     ]
    }
   ],
   "source": [
    "df_with_durations = calc_trip_times(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_time</th>\n",
       "      <th>pickup_times</th>\n",
       "      <th>Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.80</td>\n",
       "      <td>142</td>\n",
       "      <td>236</td>\n",
       "      <td>21.95</td>\n",
       "      <td>17.816667</td>\n",
       "      <td>1.640997e+09</td>\n",
       "      <td>12.797007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>236</td>\n",
       "      <td>42</td>\n",
       "      <td>13.30</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>1.640997e+09</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.97</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>10.56</td>\n",
       "      <td>8.966667</td>\n",
       "      <td>1.640998e+09</td>\n",
       "      <td>6.490706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>114</td>\n",
       "      <td>68</td>\n",
       "      <td>11.80</td>\n",
       "      <td>10.033333</td>\n",
       "      <td>1.640997e+09</td>\n",
       "      <td>6.518272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.30</td>\n",
       "      <td>68</td>\n",
       "      <td>163</td>\n",
       "      <td>30.30</td>\n",
       "      <td>37.533333</td>\n",
       "      <td>1.640997e+09</td>\n",
       "      <td>6.873890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463926</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>90</td>\n",
       "      <td>170</td>\n",
       "      <td>13.69</td>\n",
       "      <td>5.966667</td>\n",
       "      <td>1.643672e+09</td>\n",
       "      <td>13.273743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463927</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>107</td>\n",
       "      <td>75</td>\n",
       "      <td>24.45</td>\n",
       "      <td>10.650000</td>\n",
       "      <td>1.643673e+09</td>\n",
       "      <td>23.605634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463928</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>113</td>\n",
       "      <td>246</td>\n",
       "      <td>16.52</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.643672e+09</td>\n",
       "      <td>11.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463929</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.92</td>\n",
       "      <td>148</td>\n",
       "      <td>164</td>\n",
       "      <td>15.70</td>\n",
       "      <td>12.050000</td>\n",
       "      <td>1.643672e+09</td>\n",
       "      <td>14.539419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2463930</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.94</td>\n",
       "      <td>186</td>\n",
       "      <td>181</td>\n",
       "      <td>35.06</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.643673e+09</td>\n",
       "      <td>19.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2463931 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passenger_count  trip_distance  PULocationID  DOLocationID  \\\n",
       "0                    2.0           3.80           142           236   \n",
       "1                    1.0           2.10           236            42   \n",
       "2                    1.0           0.97           166           166   \n",
       "3                    1.0           1.09           114            68   \n",
       "4                    1.0           4.30            68           163   \n",
       "...                  ...            ...           ...           ...   \n",
       "2463926              0.0           1.32            90           170   \n",
       "2463927              0.0           4.19           107            75   \n",
       "2463928              0.0           2.10           113           246   \n",
       "2463929              0.0           2.92           148           164   \n",
       "2463930              0.0           8.94           186           181   \n",
       "\n",
       "         total_amount  trip_time  pickup_times      Speed  \n",
       "0               21.95  17.816667  1.640997e+09  12.797007  \n",
       "1               13.30   8.400000  1.640997e+09  15.000000  \n",
       "2               10.56   8.966667  1.640998e+09   6.490706  \n",
       "3               11.80  10.033333  1.640997e+09   6.518272  \n",
       "4               30.30  37.533333  1.640997e+09   6.873890  \n",
       "...               ...        ...           ...        ...  \n",
       "2463926         13.69   5.966667  1.643672e+09  13.273743  \n",
       "2463927         24.45  10.650000  1.643673e+09  23.605634  \n",
       "2463928         16.52  11.000000  1.643672e+09  11.454545  \n",
       "2463929         15.70  12.050000  1.643672e+09  14.539419  \n",
       "2463930         35.06  27.000000  1.643673e+09  19.866667  \n",
       "\n",
       "[2463931 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_with_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(df_with_durations):\n",
    "    df_with_durations['total_amount']= zscore(df_with_durations['total_amount'])\n",
    "    return df_with_durations\n",
    "\n",
    "df_with_durations = z_score(df_with_durations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265\n"
     ]
    }
   ],
   "source": [
    "print(max(df_with_durations['PULocationID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.cluster import KMeans\n",
    "from numpy.ma import count\n",
    "from numpy.core.umath import log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldcol  = df['PULocationID'].values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binning (df) : \n",
    "    bins  = ceil(1+3.322*log(count(df_with_durations['PULocationID'])))\n",
    "    oldcol  = df['PULocationID'].values.reshape(-1,1)\n",
    "    kmeans = KMeans(n_clusters=int(bins),  random_state=0).fit(oldcol)\n",
    "    newcol = kmeans.predict(oldcol)\n",
    "    df['PUCluster'] = newcol\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins  = ceil(1+3.322*log(count(df_with_durations['PULocationID'])))\n",
    "kmeans = KMeans(n_clusters=int(bins),  random_state=0).fit(oldcol)\n",
    "df_with_durations['PUCluster'] = kmeans.predict(oldcol)\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_len = len(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[193.89482584]\n",
      " [ 99.91232911]\n",
      " [245.84929029]\n",
      " [142.        ]\n",
      " [ 48.0027514 ]\n",
      " [164.42091529]\n",
      " [ 74.74728682]\n",
      " [228.99579152]\n",
      " [264.227877  ]\n",
      " [237.        ]\n",
      " [ 24.10200219]\n",
      " [131.98222566]\n",
      " [113.58723744]\n",
      " [210.74174618]\n",
      " [ 90.02265474]\n",
      " [ 67.84306951]\n",
      " [106.999583  ]\n",
      " [186.01118406]\n",
      " [  4.91630478]\n",
      " [169.99458794]\n",
      " [151.07820527]\n",
      " [160.9996035 ]\n",
      " [ 43.12135187]\n",
      " [137.61115718]\n",
      " [ 79.02517043]\n",
      " [233.67970595]\n",
      " [262.47235985]\n",
      " [239.00924351]\n",
      " [124.98948962]\n",
      " [224.23865127]\n",
      " [249.00153396]\n",
      " [ 12.94122131]\n",
      " [147.86499289]\n",
      " [139.99879322]\n",
      " [ 87.31348912]\n",
      " [ 34.13888889]\n",
      " [157.9826454 ]\n",
      " [143.43057456]\n",
      " [231.08923809]\n",
      " [162.        ]\n",
      " [255.52069858]\n",
      " [238.        ]\n",
      " [235.99904903]\n",
      " [141.        ]\n",
      " [179.87195903]\n",
      " [230.        ]\n",
      " [ 70.02316033]\n",
      " [ 50.14148655]\n",
      " [163.        ]\n",
      " [ 41.16703241]]\n"
     ]
    }
   ],
   "source": [
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Binning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pickup_bins(frame,month):\n",
    "    unix_pickup_times=[i for i in frame['pickup_times'].values]\n",
    "    unix_times = [1640975400,1643653800,1646073000,1648751400]\n",
    "    \n",
    "    start_pickup_unix=unix_times[month-1]\n",
    "\n",
    "    frame['pickup_bins'] = np.array(start_pickup_unix)\n",
    "    return frame\n",
    "df_with_durations = add_pickup_bins(df_with_durations,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2021_groupby = df_with_durations[['PUCluster','pickup_bins','trip_distance']].groupby(['PUCluster','pickup_bins']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep(df,month):\n",
    "    df = null_value_handled(df)\n",
    "    df = calc_trip_times(df)\n",
    "    df = z_score(df)\n",
    "    df = binning(df)\n",
    "    df = add_pickup_bins(df,month)\n",
    "    df_groupby = df_with_durations[['PUCluster','pickup_bins','trip_distance']].groupby(['PUCluster','pickup_bins']).count()\n",
    "    return df , df_groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feb_2022 = pd.read_parquet('yellow_tripdata_2022-02.parquet')\n",
    "df_march_2022 = pd.read_parquet('yellow_tripdata_2022-03.parquet')\n",
    "df_april_2022 = pd.read_parquet('yellow_tripdata_2022-04.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01 00:06:58</td>\n",
       "      <td>2022-02-01 00:19:24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>23.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01 00:38:22</td>\n",
       "      <td>2022-02-01 00:55:55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.3</td>\n",
       "      <td>30.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-02-01 00:03:20</td>\n",
       "      <td>2022-02-01 00:26:59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>35.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6.55</td>\n",
       "      <td>0.3</td>\n",
       "      <td>44.60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-01 00:08:00</td>\n",
       "      <td>2022-02-01 00:28:05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.88</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>34.80</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-02-01 00:06:48</td>\n",
       "      <td>2022-02-01 00:33:07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>N</td>\n",
       "      <td>138</td>\n",
       "      <td>125</td>\n",
       "      <td>1</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>48.66</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2022-02-01 00:06:58   2022-02-01 00:19:24              1.0   \n",
       "1         1  2022-02-01 00:38:22   2022-02-01 00:55:55              1.0   \n",
       "2         1  2022-02-01 00:03:20   2022-02-01 00:26:59              1.0   \n",
       "3         2  2022-02-01 00:08:00   2022-02-01 00:28:05              1.0   \n",
       "4         2  2022-02-01 00:06:48   2022-02-01 00:33:07              1.0   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0           5.40         1.0                  N           138           252   \n",
       "1           6.40         1.0                  N           138            41   \n",
       "2          12.50         1.0                  N           138           200   \n",
       "3           9.88         1.0                  N           239           200   \n",
       "4          12.16         1.0                  N           138           125   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1         17.0   1.75      0.5        3.90          0.00   \n",
       "1             2         21.0   1.75      0.5        0.00          6.55   \n",
       "2             2         35.5   1.75      0.5        0.00          6.55   \n",
       "3             2         28.0   0.50      0.5        0.00          3.00   \n",
       "4             1         35.5   0.50      0.5        8.11          0.00   \n",
       "\n",
       "   improvement_surcharge  total_amount  congestion_surcharge  airport_fee  \n",
       "0                    0.3         23.45                   0.0         1.25  \n",
       "1                    0.3         30.10                   0.0         1.25  \n",
       "2                    0.3         44.60                   0.0         1.25  \n",
       "3                    0.3         34.80                   2.5         0.00  \n",
       "4                    0.3         48.66                   2.5         1.25  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feb_2022.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SATVIK_DELL\\AppData\\Local\\Temp\\ipykernel_22716\\1101715340.py:3: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  return (s- np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "C:\\Users\\SATVIK_DELL\\AppData\\Local\\Temp\\ipykernel_22716\\1101715340.py:3: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  return (s- np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n",
      "C:\\Users\\SATVIK_DELL\\AppData\\Local\\Temp\\ipykernel_22716\\1101715340.py:3: DeprecationWarning: parsing timezone aware datetimes is deprecated; this will raise an error in the future\n",
      "  return (s- np.datetime64('1970-01-01T00:00:00Z'))/np.timedelta64(1, 's')\n"
     ]
    }
   ],
   "source": [
    "df_feb_2022, groupby_feb_2022= dataprep(df_feb_2022,2)\n",
    "df_march_2022, groupby_march_2022 = dataprep(df_march_2022,3)\n",
    "df_april_2022 , groupby_april_2022 = dataprep(df_april_2022,4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Dataframe only with x(i) values as jan-2015 data and y(i) values as jan-2016\n",
    "ratios = pd.DataFrame()\n",
    "ratios['Given']= jan_2021_groupby\n",
    "ratios['Prediction']= groupby_feb_2022\n",
    "ratios['Ratios']=ratios['Prediction']*1.0/ratios['Given']*1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOOTHING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the unique bins where pickup values are present for each each reigion\n",
    "\n",
    "# for each cluster region we will collect all the indices of 10min intravels in which the pickups are happened\n",
    "# we got an observation that there are some pickpbins that doesnt have any pickups\n",
    "def return_unq_pickup_bins(frame):\n",
    "    values = []\n",
    "    for i in range(0, 40):\n",
    "        new = frame[frame['PUCluster'] == i]\n",
    "        list_unq = list(set(new['pickup_bins']))\n",
    "        list_unq.sort()\n",
    "        values.append(list_unq)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_2021_unique = return_unq_pickup_bins(df_with_durations)\n",
    "feb_2022_unique = return_unq_pickup_bins(df_feb_2022)\n",
    "\n",
    "# march\n",
    "march_2022_unique = return_unq_pickup_bins(df_march_2022)\n",
    "\n",
    "# april\n",
    "april_2022_unique = return_unq_pickup_bins(df_april_2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for the  0 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  1 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  2 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  3 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  4 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  5 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  6 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  7 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  8 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  9 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  10 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  11 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  12 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  13 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  14 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  15 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  16 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  17 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  18 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  19 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  20 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  21 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  22 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  23 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  24 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  25 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  26 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  27 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  28 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  29 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  30 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  31 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  32 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  33 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  34 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  35 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  36 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  37 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  38 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n",
      "for the  39 th cluster number of 10min intavels with zero pickups:  4463\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# for each cluster number of 10min intravels with 0 pickups\n",
    "for i in range(40):\n",
    "    print(\"for the \", i, \"th cluster number of 10min intavels with zero pickups: \",\n",
    "          4464 - len(set(jan_2021_unique[i])))\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills a value of zero for every bin where no pickup data is present\n",
    "# the count_values: number pickps that are happened in each region for each 10min intravel\n",
    "# there wont be any value if there are no picksups.\n",
    "# values: number of unique bins\n",
    "\n",
    "# for every 10min intravel(pickup_bin) we will check it is there in our unique bin,\n",
    "# if it is there we will add the count_values[index] to smoothed data\n",
    "# if not we add 0 to the smoothed data\n",
    "# we finally return smoothed data\n",
    "def fill_missing(count_values, values):\n",
    "    smoothed_regions = []\n",
    "    ind = 0\n",
    "    for r in range(0, 40):\n",
    "        smoothed_bins = []\n",
    "        for i in range(4464):\n",
    "            if i in values[r]:\n",
    "                smoothed_bins.append(count_values[ind])\n",
    "                ind += 1\n",
    "            else:\n",
    "                smoothed_bins.append(0)\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fills a value of zero for every bin where no pickup data is present\n",
    "# the count_values: number pickps that are happened in each region for each 10min intravel\n",
    "# there wont be any value if there are no picksups.\n",
    "# values: number of unique bins\n",
    "\n",
    "# for every 10min intravel(pickup_bin) we will check it is there in our unique bin,\n",
    "# if it is there we will add the count_values[index] to smoothed data\n",
    "# if not we add smoothed data (which is calculated based on the methods that are discussed in the above markdown cell)\n",
    "# we finally return smoothed data\n",
    "import math\n",
    "\n",
    "\n",
    "def smoothing(count_values, values):\n",
    "    smoothed_regions = []  # stores list of final smoothed values of each reigion\n",
    "    ind = 0\n",
    "    repeat = 0\n",
    "    smoothed_value = 0\n",
    "    for r in range(0, 40):\n",
    "        smoothed_bins = []  # stores the final smoothed values\n",
    "        repeat = 0\n",
    "        for i in range(4464):\n",
    "            if repeat != 0:  # prevents iteration for a value which is already visited/resolved\n",
    "                repeat -= 1\n",
    "                continue\n",
    "            if i in values[r]:  # checks if the pickup-bin exists\n",
    "                # appends the value of the pickup bin if it exists\n",
    "                smoothed_bins.append(count_values[ind])\n",
    "            else:\n",
    "                if i != 0:\n",
    "                    right_hand_limit = 0\n",
    "                    for j in range(i, 4464):\n",
    "                        # searches for the left-limit or the pickup-bin value which has a pickup value\n",
    "                        if j not in values[r]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit = j\n",
    "                            break\n",
    "                    if right_hand_limit == 0:\n",
    "                        # Case 1: When we have the last/last few values are found to be missing,hence we have no right-limit here\n",
    "                        smoothed_value = count_values[ind-1] * \\\n",
    "                            1.0/((4463-i)+2)*1.0\n",
    "                        for j in range(i, 4464):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat = (4463-i)\n",
    "                        ind -= 1\n",
    "                    else:\n",
    "                        # Case 2: When we have the missing values between two known values\n",
    "                        smoothed_value = (\n",
    "                            count_values[ind-1]+count_values[ind])*1.0/((right_hand_limit-i)+2)*1.0\n",
    "                        for j in range(i, right_hand_limit+1):\n",
    "                            smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                        smoothed_bins[i-1] = math.ceil(smoothed_value)\n",
    "                        repeat = (right_hand_limit-i)\n",
    "                else:\n",
    "                    # Case 3: When we have the first/first few values are found to be missing,hence we have no left-limit here\n",
    "                    right_hand_limit = 0\n",
    "                    for j in range(i, 4464):\n",
    "                        if j not in values[r]:\n",
    "                            continue\n",
    "                        else:\n",
    "                            right_hand_limit = j\n",
    "                            break\n",
    "                    smoothed_value = count_values[ind] * \\\n",
    "                        1.0/((right_hand_limit-i)+1)*1.0\n",
    "                    for j in range(i, right_hand_limit+1):\n",
    "                        smoothed_bins.append(math.ceil(smoothed_value))\n",
    "                    repeat = (right_hand_limit-i)\n",
    "            ind += 1\n",
    "        smoothed_regions.extend(smoothed_bins)\n",
    "    return smoothed_regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling Missing values of Jan-2015 with 0\n",
    "# here in jan_2015_groupby dataframe the trip_distance represents the number of pickups that are happened\n",
    "jan_2021_fill = fill_missing(\n",
    "    jan_2021_groupby['trip_distance'].values, jan_2021_unique)\n",
    "\n",
    "# Smoothing Missing values of Jan-2015\n",
    "jan_2021_smooth = smoothing(\n",
    "    jan_2021_groupby['trip_distance'].values, jan_2021_unique)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan-2015 data is smoothed, Jan,Feb & March 2016 data missing values are filled with zero\n",
    "jan_2021_smooth = smoothing(\n",
    "    jan_2021_groupby['trip_distance'].values, jan_2021_unique)\n",
    "feb_2022_smooth = fill_missing(\n",
    "    groupby_feb_2022['trip_distance'].values, feb_2022_unique)\n",
    "march_2022_smooth = fill_missing(\n",
    "    groupby_march_2022['trip_distance'].values, march_2022_unique)\n",
    "april_2022_smooth = fill_missing(\n",
    "    groupby_april_2022['trip_distance'].values, april_2022_unique)\n",
    "\n",
    "# Making list of all the values of pickup data in every bin for a period of 3 months and storing them region-wise\n",
    "regions_cum = []\n",
    "\n",
    "# a =[1,2,3]\n",
    "# b = [2,3,4]\n",
    "# a+b = [1, 2, 3, 2, 3, 4]\n",
    "\n",
    "# number of 10min indices for jan 2015= 24*31*60/10 = 4464\n",
    "# number of 10min indices for jan 2016 = 24*31*60/10 = 4464\n",
    "# number of 10min indices for feb 2016 = 24*29*60/10 = 4176\n",
    "# number of 10min indices for march 2016 = 24*31*60/10 = 4464\n",
    "# regions_cum: it will contain 40 lists, each list will contain 4464+4176+4464 values which represents the number of pickups\n",
    "# that are happened for three months in 2016 data\n",
    "\n",
    "for i in range(0, 40):\n",
    "    regions_cum.append(feb_2022_smooth[4464*i:4464*(\n",
    "        i+1)]+march_2022_smooth[4176*i:4176*(i+1)]+april_2022_smooth[4464*i:4464*(i+1)])\n",
    "\n",
    "# print(len(regions_cum))\n",
    "# 40\n",
    "# print(len(regions_cum[0]))\n",
    "# 13104"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28a1ca007e8113ad6d8a4a18f50bf41d6255f689e14947ced028dea5fcb864ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
